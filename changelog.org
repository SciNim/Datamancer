* v0.3.0 (To be finalized...)
- *MAJOR, BREAKING*: Add experimental support for "non-generic generic
  =Columns=". Essentially, from many procedures it is now possible to
  assign data types that are normally not supported to be stored
  inside of a =DataFrame=. With a lot of macro magic however, we
  generate a new =Column= type that is able to store such a data
  type. Then we return a new =DataFrame= for the user that uses the
  new =Column= type. For that reason =DataFrame= is now a generic type
  (generic over the =Column= type) and the notion of the =Column= has
  become a =ColumnLike= concept. This was the easiest way to add
  support for things like:
  - =DateTime=
  - arbitrary =unchained= units in a DF
  - =Measurement= objects =Measuremancer=
  - ... whatever else you can think of. As long as it fits into a
    =Tensor[T]=, you can now place it into a DF!
  See XXX for a short introduction on the feature.
* v0.2.0
- constant =DataFrame= columns have seen improvements. Before most
  operations on them would convert them to a non-constant column,
  often forced to convert to an object column. Now, most operations
  (that make sense) are supported on constants themselves and if a
  non-constant conversion is required, it aims to use the type
  corresponding to the underlying =Value= kind of the constant. That
  way conversions of constants to full columns should now lead to
  native (float, int, string, bool) tensors (unless an operation with
  another native, incompatible type is performed)
- some bugs were fixed that could cause reference semantics of
  dataframes to shine through when using =filter=
- *BREAKING*: the =toValueKind= procedure now takes a =Column= instead
  of a =ColumnKind=. This is to be able to handle the constant to full
  conversion properly. Note: A deprecated variant of the former
  version is still around!
- add =filterToIdx=, which takes a DF and a sequence / tensor of
  integers. The procedure will keep only those rows of the DF whose
  indices are part of the seq/Tensor
- slight performance improvements for the parsing of CSV files (larger
  for string heavy files) by avoiding an unnecessary =newString= call
  (yeah, =setLen= resizes for you if needed...)
- allow more valid Nim code inside of =f{}= formulas, e.g. if
  expressions and block statements
- fix type determinations in =f{}= formulas, if a procedure with
  default parameters, but no explicit type information is given.  
- certain expressions in =f{}= formulas (for example
  =isNaN(idx("foo"))=) could produce unintended CT errors and work now
  (sorry, had to add a =when compiles= check :( ).
- experimental support for "full formulas" as I call them that allow
  to have more control over variables in the scope of the formula:
  #+begin_src nim
  formula:
    preface:
      foo in df["Foo", float]
      bar in baz(df["Bar", int])
    loop:
      bar^2.float + foo  
  #+end_src
  allows for custom variable names inside of the context (and more
  importantly) to perform a full column operation (e.g. =baz=) on a
  column *before* the loop and use the elements of that operation
  inside of the loop. Note that this is _not_ for *reducing* operations
  on columns (i.e. =mean(df["Bar", float])=)! It is still planned to
  lift reducing operations out of the loop body, but that is still
  pending.
- *SEMI-BREAKING*: add preliminary support for reducing formulas that require a =for=
  loop. This (currently) allows for ~res += <formula>~ like statements
  inside of a loop instead of just ~res = <formula>~ where in the
  latter the formula must produce a scalar by itself (i.e. does not
  allow *element wise* access to columns). Now a formula that accesses
  a single element via =idx(...)= will produce a loop with an
  accumulation.
  Note: to make use of this feature you *must* use the full formula
  syntax, as otherwise the default value of =res= is unclear.
  #+begin_src nim
  formula:
    preface:
      var res = 1.0
      Bidx in df["B", float]
    loop:
      res *= Bidx * 1.5
  #+end_src
- add =lag=, =lead= procedures that take a =Tensor/Column= and return
  a new =Tensor/Column= that is shiftet forward / backward N elements
  (the left overs are zeroed by default, but adjustable using =fill= argument)
- the =showBrowser= helper to view a =DataFrame= in the browser now
  adds an additional "index" column
- improve performance of =groups= iterator (particularly in cases
  where the DF is already sorted / the sorting is cheap)
- fix type deduction issues in formulas using dot expressions for
  certain cases  
* v0.1.11
- add convenience comparison operators for =Value= elements of a
  column with regular types *within a =f{}= formula* (they are emitted
  as templates into the closure scope to avoid having them available
  in all scopes).
  Use the =convenienceValueComparisons= template to emit them to a
  local scope if desired outside formula scopes.
* v0.1.10
- make sure to only import and export =arraymancer/tensor= submodule
- fix CSV parsing wrt. empty fields (treated as NaN) and explicit NaN
  & Inf values
- fix CSV parsing of files with extraneous newlines
- fix CSV parsing with missing values at the end of a line (becomes
  =NaN=)
- fix CSV parsing of empty fields if missing in first row and element
  is *not* float
- add more parsing tests
* v0.1.9
- add basic implementation of =spread= (inverse of =gather=; similar
  to dplyr =pivot_wider=). The current implementation is rather basic
  and performance may be suboptimal for very large data frames.
- add =null= helper to create a =VNull Value=
- significantly improve the docs of the =dataframe.nim= module.
- fixes an issue where unique column reference names were combined
  into the same column due to a bad name generation algorithm
- significantly improves performance in applications in which
  allocation of memory is a bottleneck (tensors were zero
  initialized).
- disable formula output at CT by default. Compile with
  =-d:echoFormulas= to see the output.
- remove CT warnings for unrelated stuff (node kinds)  
* v0.1.8
- avoid some object conversions in column operations (ref #11)
- add ~[]=~ overloads for columns for slice assignments
- *significantly* improve performance of =mutate/transmute= operations
  for grouped dataframes (O(150,000) groups in < 0.5 s possible now)
- fixes #12 by avoiding hashing of columns. Some performance
  regression in =innerJoin=, =setDiff= (~2x slower in bad cases).    
* v0.1.7
- allow assignment of constants in =seqsToDf=
- allow assignment of scalars to DF as column directly
- add filename argument to =showBrowser=
- make =compileFormulaImpl= actually typed to make formulas work
  correctly inside of generics (ref =ggplotnim=
  https://github.com/Vindaar/ggplotnim/issues/116
- change internal macro type logic to use strings
  
* v0.1.6
- fix slicing of constant columns

* v0.1.5
- fully qualify =Value= on scalar formula construction

* v0.1.4
- fix formulas (and type deduction) for certain use cases involving
  =nnkBracketExpr= that are *not* references to columns

* v0.1.3
- improve type deduction capabilities for infix nodes
- add overload for =drop= that doesn't just work on a mutable data
  frame
- fix reference semantics issues if DF is modified and visible in
  result (only data is shared, but columns should be respected)
- =arrange= now also takes a =varargs[string]= instead of a
  =seq=. While there is still a bug of not properly being able to use
  varargs, at least an array is possible (and hopefully at some point
  proper varargs).

* v0.1.2
- CSV parser is more robust, can handle unnammed columns
- explicit types in =idx=, =col= column reference finally works
  (e.g. =idx("foo", float)= accesses the column "foo" as a float
  tensor overwriting type deductions and type hints)

* v0.1.1
- allow =nnkMacroDef= in =findType=
- add development notes and ideas about rewrite of formula macro in =notes/formula_dev_notes.org=

* v0.1.0

- initial version of Datamancer based on =ggplotnim= data frame with
  major formula macro rewrite
